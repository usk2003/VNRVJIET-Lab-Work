{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyMPQkus7+/u9JM+qlu41iUu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **ML Lab - Decision Trees**\n","Urlana Suresh Kumar - 22071A6662"],"metadata":{"id":"hIt5h3wdAfdR"}},{"cell_type":"markdown","source":["# Decision Trees and Bag of Words in Python\n","\n","In this notebook, we will explore two different concepts:\n","1. **Decision Trees**: Using Gini index and entropy for training decision tree classifiers.\n","2. **Bag of Words**: Using `CountVectorizer` to convert text data into a matrix of token counts."],"metadata":{"id":"xKj33tIwAnqF"}},{"cell_type":"markdown","source":["## Step 1: Importing Required Libraries"],"metadata":{"id":"OQxA3BjhAsrh"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"eTdaB93NAJKj"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.metrics import confusion_matrix\n","from sklearn.model_selection import train_test_split\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import classification_report\n","from sklearn.feature_extraction.text import CountVectorizer"]},{"cell_type":"markdown","source":["## Step 2: Importing Dataset\n"],"metadata":{"id":"BzBqiEIzAwUh"}},{"cell_type":"code","source":["# Function importing Dataset\n","def importdata():\n","    balance_data = pd.read_csv(\n","        'https://archive.ics.uci.edu/ml/machine-learning-' +\n","        'databases/balance-scale/balance-scale.data',\n","        sep=',', header=None)\n","\n","    # Printing the dataset shape and first few rows\n","    print(\"Dataset Length: \", len(balance_data))\n","    print(\"Dataset Shape: \", balance_data.shape)\n","    print(\"Dataset: \", balance_data.head())\n","    return balance_data"],"metadata":{"id":"X53tMl7HA0WG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Step 3: Splitting Dataset into Training and Testing"],"metadata":{"id":"CvJtv6MrANk3"}},{"cell_type":"code","source":["# Function to split the dataset\n","def splitdataset(balance_data):\n","    # Separating the target variable\n","    X = balance_data.values[:, 1:5]\n","    Y = balance_data.values[:, 0]\n","\n","    # Splitting the dataset into train and test\n","    X_train, X_test, y_train, y_test = train_test_split(\n","        X, Y, test_size=0.3, random_state=100)\n","\n","    return X, Y, X_train, X_test, y_train, y_test"],"metadata":{"id":"-7K43lLGA5Vs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Step 4: Training Decision Tree using Gini Index"],"metadata":{"id":"T1SyDFMrA8ZE"}},{"cell_type":"code","source":["# Function to perform training with Gini Index\n","def train_using_gini(X_train, X_test, y_train):\n","    # Creating the classifier object\n","    clf_gini = DecisionTreeClassifier(criterion=\"gini\", random_state=100, max_depth=3, min_samples_leaf=5, class_weight='balanced')\n","    clf_entropy = DecisionTreeClassifier(criterion=\"entropy\", random_state=100, max_depth=3, min_samples_leaf=5, class_weight='balanced')\n","\n","\n","    # Performing training\n","    clf_gini.fit(X_train, y_train)\n","    return clf_gini"],"metadata":{"id":"WO1tqgRyA_9f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Step 5: Training Decision Tree using Entropy"],"metadata":{"id":"ER4ssJQBBDwN"}},{"cell_type":"code","source":["# Function to perform training with Entropy\n","def tarin_using_entropy(X_train, X_test, y_train):\n","    # Decision tree with entropy\n","    clf_entropy = DecisionTreeClassifier(\n","        criterion=\"entropy\", random_state=100, max_depth=3, min_samples_leaf=5)\n","\n","    # Performing training\n","    clf_entropy.fit(X_train, y_train)\n","    return clf_entropy"],"metadata":{"id":"7sIOMlnNBE40"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Step 6: Making Predictions"],"metadata":{"id":"UvUH_2fEBIzE"}},{"cell_type":"code","source":["# Function to make predictions\n","def prediction(X_test, clf_object):\n","    # Prediction on test data\n","    y_pred = clf_object.predict(X_test)\n","    print(\"Predicted values:\")\n","    print(y_pred)\n","    return y_pred"],"metadata":{"id":"ng8Gw_4ABKHi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Step 7: Calculating Accuracy"],"metadata":{"id":"Chn_LJsIBNfm"}},{"cell_type":"code","source":["# Function to calculate accuracy\n","def cal_accuracy(y_test, y_pred):\n","    print(\"Confusion Matrix: \", confusion_matrix(y_test, y_pred))\n","    print(\"Accuracy : \", accuracy_score(y_test, y_pred)*100)\n","    print(\"Report : \", classification_report(y_test, y_pred, zero_division=0))  # Set"],"metadata":{"id":"nnMUs46pBO7h"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Main Execution Code\n"],"metadata":{"id":"jFsLPoXzBSsF"}},{"cell_type":"code","source":["# Driver code\n","def main():\n","    # Building Phase\n","    data = importdata()\n","    X, Y, X_train, X_test, y_train, y_test = splitdataset(data)\n","    clf_gini = train_using_gini(X_train, X_test, y_train)\n","    clf_entropy = tarin_using_entropy(X_train, X_test, y_train)\n","\n","    # Operational Phase\n","    print(\"Results Using Gini Index:\")\n","    # Prediction using gini\n","    y_pred_gini = prediction(X_test, clf_gini)\n","    cal_accuracy(y_test, y_pred_gini)\n","\n","    print(\"Results Using Entropy:\")\n","    # Prediction using entropy\n","    y_pred_entropy = prediction(X_test, clf_entropy)\n","    cal_accuracy(y_test, y_pred_entropy)\n","\n","# Calling main function\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vqHScbg4BVc5","executionInfo":{"status":"ok","timestamp":1731325327562,"user_tz":-330,"elapsed":446,"user":{"displayName":"Suresh Kumar Urlana (Study)","userId":"02832329327666247405"}},"outputId":"f24dd881-ac9a-40f6-f406-7c66aa650dc3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset Length:  625\n","Dataset Shape:  (625, 5)\n","Dataset:     0  1  2  3  4\n","0  B  1  1  1  1\n","1  R  1  1  1  2\n","2  R  1  1  1  3\n","3  R  1  1  1  4\n","4  R  1  1  1  5\n","Results Using Gini Index:\n","Predicted values:\n","['R' 'B' 'R' 'B' 'R' 'B' 'R' 'L' 'B' 'R' 'R' 'B' 'B' 'B' 'R' 'B' 'R' 'L'\n"," 'R' 'R' 'B' 'R' 'B' 'L' 'R' 'L' 'B' 'L' 'R' 'L' 'L' 'L' 'R' 'L' 'L' 'L'\n"," 'B' 'L' 'B' 'B' 'L' 'L' 'L' 'L' 'R' 'R' 'L' 'L' 'R' 'L' 'B' 'R' 'B' 'B'\n"," 'R' 'L' 'R' 'R' 'L' 'B' 'B' 'L' 'L' 'B' 'L' 'B' 'B' 'R' 'L' 'L' 'B' 'L'\n"," 'R' 'L' 'R' 'L' 'L' 'R' 'R' 'B' 'R' 'B' 'L' 'B' 'R' 'R' 'R' 'L' 'R' 'L'\n"," 'B' 'R' 'L' 'L' 'L' 'R' 'R' 'L' 'B' 'B' 'L' 'L' 'L' 'R' 'R' 'R' 'B' 'R'\n"," 'R' 'B' 'L' 'L' 'R' 'R' 'L' 'B' 'R' 'L' 'B' 'R' 'B' 'R' 'R' 'L' 'B' 'L'\n"," 'L' 'L' 'L' 'R' 'R' 'R' 'R' 'L' 'R' 'R' 'R' 'L' 'L' 'R' 'L' 'R' 'L' 'R'\n"," 'L' 'B' 'R' 'L' 'B' 'R' 'L' 'R' 'B' 'L' 'R' 'R' 'L' 'R' 'R' 'R' 'L' 'L'\n"," 'B' 'L' 'R' 'L' 'R' 'R' 'B' 'R' 'B' 'L' 'B' 'R' 'B' 'B' 'R' 'L' 'L' 'R'\n"," 'B' 'R' 'L' 'L' 'L' 'L' 'R' 'R']\n","Confusion Matrix:  [[ 2  5  6]\n"," [23 51 11]\n"," [20 14 56]]\n","Accuracy :  57.97872340425532\n","Report :                precision    recall  f1-score   support\n","\n","           B       0.04      0.15      0.07        13\n","           L       0.73      0.60      0.66        85\n","           R       0.77      0.62      0.69        90\n","\n","    accuracy                           0.58       188\n","   macro avg       0.51      0.46      0.47       188\n","weighted avg       0.70      0.58      0.63       188\n","\n","Results Using Entropy:\n","Predicted values:\n","['R' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'R' 'R' 'R' 'R' 'L' 'L' 'R' 'L' 'R' 'L'\n"," 'L' 'R' 'L' 'R' 'L' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'L' 'L'\n"," 'L' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'R' 'R' 'L' 'L' 'R' 'L' 'L' 'R' 'L' 'L'\n"," 'R' 'L' 'R' 'R' 'L' 'R' 'R' 'R' 'L' 'L' 'R' 'L' 'L' 'R' 'L' 'L' 'L' 'R'\n"," 'R' 'L' 'R' 'L' 'R' 'R' 'R' 'L' 'R' 'L' 'L' 'L' 'L' 'R' 'R' 'L' 'R' 'L'\n"," 'R' 'R' 'L' 'L' 'L' 'R' 'R' 'L' 'L' 'L' 'R' 'L' 'L' 'R' 'R' 'R' 'R' 'R'\n"," 'R' 'L' 'R' 'L' 'R' 'R' 'L' 'R' 'R' 'L' 'R' 'R' 'L' 'R' 'R' 'R' 'L' 'L'\n"," 'L' 'L' 'L' 'R' 'R' 'R' 'R' 'L' 'R' 'R' 'R' 'L' 'L' 'R' 'L' 'R' 'L' 'R'\n"," 'L' 'R' 'R' 'L' 'L' 'R' 'L' 'R' 'R' 'R' 'R' 'R' 'L' 'R' 'R' 'R' 'R' 'R'\n"," 'R' 'L' 'R' 'L' 'R' 'R' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'L' 'L' 'L' 'L' 'R'\n"," 'R' 'R' 'L' 'L' 'L' 'R' 'R' 'R']\n","Confusion Matrix:  [[ 0  6  7]\n"," [ 0 63 22]\n"," [ 0 20 70]]\n","Accuracy :  70.74468085106383\n","Report :                precision    recall  f1-score   support\n","\n","           B       0.00      0.00      0.00        13\n","           L       0.71      0.74      0.72        85\n","           R       0.71      0.78      0.74        90\n","\n","    accuracy                           0.71       188\n","   macro avg       0.47      0.51      0.49       188\n","weighted avg       0.66      0.71      0.68       188\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]}]},{"cell_type":"markdown","source":["# Bag of Words Example using CountVectorizer"],"metadata":{"id":"G9bw-__gCB5b"}},{"cell_type":"code","source":["# A list of sentences\n","sentences = [\"This pasta is very tasty and affordable.\",\n","             \"This pasta is not tasty and is affordable.\",\n","             \"This pasta is very very delicious.\"]\n","\n","# Create object for count vectorizer\n","countvectorizer = CountVectorizer()\n","\n","# Fit corpus to object of count vectorizer\n","X = countvectorizer.fit_transform(sentences)\n","\n","# Convert result to array for visualization\n","result = X.toarray()\n","print(f\"Result of bag of words: {result}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yM6xp_x1CJM2","executionInfo":{"status":"ok","timestamp":1731325377507,"user_tz":-330,"elapsed":460,"user":{"displayName":"Suresh Kumar Urlana (Study)","userId":"02832329327666247405"}},"outputId":"2b52830e-8aa3-47b0-e7a1-a5c97014543e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Result of bag of words: [[1 1 0 1 0 1 1 1 1]\n"," [1 1 0 2 1 1 1 1 0]\n"," [0 0 1 1 0 1 0 1 2]]\n"]}]}]}
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMo3Wo0KNyha6eEmoEgURYn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **ML Lab - Model Evaluation Techniques**\n","Urlana Suresh Kumar - 22071A6662"],"metadata":{"id":"1gD9ge_Ubwex"}},{"cell_type":"markdown","source":["# Model Validation Techniques\n","\n","In this notebook, we will explore three different model validation techniques:\n","1. **Holdout Validation**\n","2. **K-Fold Cross-Validation**\n","3. **Bootstrap Sampling**\n","\n","We'll use the Iris dataset and RandomForestClassifier from `sklearn` to demonstrate these validation techniques.\n","\n"],"metadata":{"id":"J11zU-uvfMKW"}},{"cell_type":"markdown","source":["## Importing Libraries and Dataset"],"metadata":{"id":"Nu1rlA_9f24K"}},{"cell_type":"code","source":["# Import necessary libraries\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score\n","from sklearn.datasets import load_iris\n","\n","# Load the Iris dataset\n","data = load_iris()\n","X = data.data  # Features\n","y = data.target  # Target"],"metadata":{"id":"LEmwJ8ytf0qa","executionInfo":{"status":"ok","timestamp":1731333154184,"user_tz":-330,"elapsed":427,"user":{"displayName":"Suresh Kumar Urlana (Study)","userId":"02832329327666247405"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["## 1. Holdout Validation\n","\n","Holdout validation is a simple approach where we split the dataset into two parts: training and testing. We train the model on the training data and evaluate its performance on the test data."],"metadata":{"id":"1hFSBbRbfc1g"}},{"cell_type":"code","source":["# Holdout Validation: Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","# Train a RandomForest model\n","model = RandomForestClassifier(random_state=42)\n","model.fit(X_train, y_train)\n","\n","# Evaluate the model on the test set\n","y_pred = model.predict(X_test)\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Holdout Validation Accuracy:\", accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"FKYNFmWVff_D","executionInfo":{"status":"ok","timestamp":1731333112136,"user_tz":-330,"elapsed":12083,"user":{"displayName":"Suresh Kumar Urlana (Study)","userId":"02832329327666247405"}},"outputId":"5956f1b7-cd14-42e5-e776-65659e2107cc"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Holdout Validation Accuracy: 1.0\n"]}]},{"cell_type":"markdown","source":["## 2. K-Fold Cross-Validation\n","In K-Fold Cross-Validation, the data is split into K subsets or \"folds.\" The model is trained on K-1 folds and tested on the remaining fold. This process is repeated for each fold, and the average performance is computed."],"metadata":{"id":"0G7OMRdCgDWG"}},{"cell_type":"code","source":["# Import necessary libraries\n","from sklearn.model_selection import KFold, cross_val_score\n","\n","# K-Fold Cross-Validation: Split the data into 5 folds\n","kf = KFold(n_splits=5, shuffle=True, random_state=42)\n","model = RandomForestClassifier(random_state=42)\n","\n","# Cross-validate and get accuracy scores\n","scores = cross_val_score(model, X, y, cv=kf, scoring='accuracy')\n","print(\"K-Fold Cross-Validation Accuracy:\", scores)\n","print(\"Mean Accuracy:\", scores.mean())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"77IBFe3IgJW4","executionInfo":{"status":"ok","timestamp":1731333241046,"user_tz":-330,"elapsed":2363,"user":{"displayName":"Suresh Kumar Urlana (Study)","userId":"02832329327666247405"}},"outputId":"7e6f96d2-72dc-40b0-dd05-beff234c99cc"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["K-Fold Cross-Validation Accuracy: [1.         0.96666667 0.93333333 0.93333333 0.96666667]\n","Mean Accuracy: 0.9600000000000002\n"]}]},{"cell_type":"markdown","source":["## 3. Bootstrap Sampling\n","Bootstrap sampling involves generating multiple samples from the dataset by resampling with replacement. Each sample is used to train a model, and the out-of-bag (OOB) samples are used for validation. This technique is commonly used in ensemble methods like Random Forest."],"metadata":{"id":"gzJ7eROBgNI_"}},{"cell_type":"code","source":["# Import necessary libraries\n","from sklearn.utils import resample\n","\n","# Bootstrap Sampling: Perform resampling 100 times\n","n_iterations = 100  # Number of bootstrap samples\n","n_size = int(len(X) * 0.8)  # 80% of data for each bootstrap sample\n","bootstrap_scores = []\n","\n","for i in range(n_iterations):\n","    # Bootstrap sample\n","    X_bs, y_bs = resample(X, y, n_samples=n_size, random_state=i)\n","\n","    # Out-of-Bag data\n","    X_oob = np.array([x for x in X if x.tolist() not in X_bs.tolist()])\n","    y_oob = np.array([y[i] for i, x in enumerate(X) if x.tolist() not in X_bs.tolist()])\n","\n","    # Train a RandomForest model\n","    model = RandomForestClassifier(random_state=42)\n","    model.fit(X_bs, y_bs)\n","\n","    # Evaluate on OOB data if available\n","    if len(y_oob) > 0:\n","        y_oob_pred = model.predict(X_oob)\n","        oob_accuracy = accuracy_score(y_oob, y_oob_pred)\n","        bootstrap_scores.append(oob_accuracy)\n","\n","# Final accuracy\n","print(\"Bootstrap Sampling OOB Accuracy:\", np.mean(bootstrap_scores))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"IL0e4IlhgPKH","executionInfo":{"status":"ok","timestamp":1731333287395,"user_tz":-330,"elapsed":24050,"user":{"displayName":"Suresh Kumar Urlana (Study)","userId":"02832329327666247405"}},"outputId":"7226a2ac-a7bd-4bae-e4a4-6ca4bfe3fda2"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Bootstrap Sampling OOB Accuracy: 0.9520959751552224\n"]}]},{"cell_type":"markdown","source":["## Conclusion\n","\n","In this notebook, we demonstrated three model validation techniques: Holdout Validation, K-Fold Cross-Validation, and Bootstrap Sampling. Each method offers different ways to assess the performance of a model:\n","\n","- **Holdout Validation**: The dataset is split into a training and testing set, and the model's performance is evaluated on the test set. The accuracy achieved was 100% in this example.\n","- **K-Fold Cross-Validation**: The dataset is divided into 5 folds. The model is trained on 4 folds and tested on the remaining fold. This process is repeated, and the average accuracy is calculated.\n","- **Bootstrap Sampling**: Multiple bootstrap samples (with replacement) are drawn from the data, and the model is trained and evaluated on out-of-bag samples. This provides an estimate of how the model would perform on unseen data.\n","\n","Each technique offers a unique perspective on model validation and can be chosen based on the specific use case."],"metadata":{"id":"OcuvoxfGgUmq"}}]}